{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9616536b",
   "metadata": {},
   "source": [
    "# 入门 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bf10f",
   "metadata": {},
   "source": [
    " **导入pytorch包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4969a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f347c",
   "metadata": {},
   "source": [
    "**创建一个行向量x，包含0到12的整数，它是默认创建整数，也可以指定创建浮点数，上面每个值被称为张量的元素，除非额外指定，否则张量存储到内存，并基于cpu计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318ddcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4a27f",
   "metadata": {},
   "source": [
    "**通过shape访问张量x（沿每个轴的长度）的形状**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1d5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7daf3",
   "metadata": {},
   "source": [
    "**张量中元素个数，即形状的所有元素乘积，可以检查它大小**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008c1884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73c1ea",
   "metadata": {},
   "source": [
    "**改变张量的形状，但是reshape不能改变它数量和元素值，注意，它可以改变张量的形状，但不会改变张量的大小，而且如果你故意整个大小不同的张量来运行会报错**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996da143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=x.reshape(3,4)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9788392",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 4]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m b\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      2\u001b[0m b\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[4, 4]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "b=x.reshape(4,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54f990",
   "metadata": {},
   "source": [
    "**可以不用手动来指定维度，比如如果我们目标形状为（高度，宽度），那么知道宽度，把高度搞为-1它就会自动计算出高度**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32271c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=x.reshape(-1,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098eb83",
   "metadata": {},
   "source": [
    "**创建全为0的张量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b8fb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5d5b3",
   "metadata": {},
   "source": [
    "**创建全为1的张量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182f812d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6317d",
   "metadata": {},
   "source": [
    "**创建随机数张量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a4d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2501, -0.4026, -0.3977,  0.3448],\n",
       "        [ 0.9936,  0.5676, -0.1477,  1.7575],\n",
       "        [-1.5782,  3.0201,  0.0659, -1.2529]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551fb1e",
   "metadata": {},
   "source": [
    "**通过提供包含数值的python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。在这里，外层列表对应于轴0，内层列表对应于轴1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e5c4ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 3, 4],\n",
       "        [3, 2, 6, 4],\n",
       "        [9, 7, 5, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2,1,3,4],[3,2,6,4],[9,7,5,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e61382",
   "metadata": {},
   "source": [
    "# 运算符 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23d46a",
   "metadata": {},
   "source": [
    "**可以在同一形状的任意两个张量上执行按元素操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e96fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1.0,2,4,8])\n",
    "y=torch.tensor([2,2,2,2])\n",
    "x+y,x-y,x*y,x/y,x**y  # **是求幂运算符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424b13e",
   "metadata": {},
   "source": [
    "**求幂运算符，exp是对输入input逐元素进行以自然数e ee为底指数运算。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61339cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d431a90",
   "metadata": {},
   "source": [
    "**也可以多张张量拼接，端对端叠成更大张量，我们只需提供张量列表，以及沿哪个轴连接，dim就是设置沿哪个轴的参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f01c072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(12,dtype=torch.float32).reshape((3,4))\n",
    "y=torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "torch.cat((x,y),dim=0),torch.cat((x,y),dim=1)# dim=0沿着y轴，dim=1沿着x轴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35b62e",
   "metadata": {},
   "source": [
    "**如果要通过逻辑运算符构建二维张量，是每个位置都进行运算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "766a796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x==y #它是对每个位置今昔那个对应，如果一个位置上数一样，会显示true，反之会false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b716f8b",
   "metadata": {},
   "source": [
    "**对所有张量求和，它是所有元素相加**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbc41ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072a8d2",
   "metadata": {},
   "source": [
    "# 广播机制 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd9ea9",
   "metadata": {},
   "source": [
    "**广播机制是用来操作两张形状不同的张量来使他可以进行运算**\n",
    "**工作方式：**\n",
    "  （1）适当复制元素来扩展一到俩个数组，以便转换后，他们两个张量形状相同\n",
    "  （2）对生产的数组执行按元素操作\n",
    "   在大多数情况，我们将沿着数组中长度为1的轴进行广播，例子如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6232e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(3).reshape((3,1))\n",
    "b=torch.arange(2).reshape((1,2))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff50d0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a6185",
   "metadata": {},
   "source": [
    "因为a和b分别为3x1与1x2的矩阵，如果相加，因为形状不匹配，所以它会广播成为更大的3x2矩阵，原理是矩阵a复制列，b复制行，按元素相加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b0094",
   "metadata": {},
   "source": [
    "# 索引与切片 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856cd1c",
   "metadata": {},
   "source": [
    "跟python数组一样，张量里面元素也是可以进行索引访问，第一个元素索引是0，最后一个索引是-1，可以指定范围来包含第一个和最后一个之前的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0914e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]),\n",
       " tensor([ 8,  9, 10, 11]),\n",
       " tensor([[ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " q[0],q[-1],q[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266148e",
   "metadata": {},
   "source": [
    "除了读，我们还可以通过指定索引来写入元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "337ab915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  9,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[1,2]=9\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c1b3a",
   "metadata": {},
   "source": [
    "如果想为多个元素赋予相同的值，只需要索引所有元素，然后为他们赋值即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498df87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 12, 12, 12],\n",
       "        [12, 12, 12, 12],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0:2, :]=12\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e1fa85",
   "metadata": {},
   "source": [
    "# 节省内存 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3fbf4",
   "metadata": {},
   "source": [
    "执行一些操作可能会导致为结果新分配内存。如，我们用Y=X+Y。我们可以将取消引用Y指向的张量，而是指向新分配被内存处的张量。\n",
    "\n",
    "注：id()函数可返回对象的内存地址          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6f35312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before=id(y)\n",
    "y=y+x\n",
    "id(y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a9b65",
   "metadata": {},
   "source": [
    "**这是不可取的，原因如下**\n",
    "\n",
    "  （1）因为机器学习中参数很多，而且更新频率很快，所以最好不要进行不必要的内存分配，希望可以原地执行更新\n",
    "\n",
    "  （2）如果不原地更新，其他引用还是会指向旧的内存位置，这样我们某些代码会无意中引用旧参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e4fd3",
   "metadata": {},
   "source": [
    "解决办法有2个\n",
    "\n",
    "（1）切片表示法：将操作的结果分配给先前分配的数组，如 Y[:]=<expression>.例子是通过创造一个z来比较俩内存，注： torch.zeros_like:生成和括号内变量维度维度一致的全是零的内容。\n",
    " （2）跟c语言缩写一个样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d6bc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "id(z):  1272596903120\n",
      "id(z):  1272596903120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#方法1\n",
    "#验证方法1\n",
    "z=torch.zeros_like(y)\n",
    "print(z)\n",
    "print('id(z): ',id(z))\n",
    "z[:]=x+y\n",
    "print('id(z): ',id(z))\n",
    "#验证方法2\n",
    "before=id(y)\n",
    "y[:]=y+x\n",
    "id(y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33d08299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before=id(y)\n",
    "y+=x\n",
    "id(y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b3cea",
   "metadata": {},
   "source": [
    "# 转换成其他python对象 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10294ae6",
   "metadata": {},
   "source": [
    "将框架定义的张量转换为numpy张量很简单，反之也很简单。torch张量和numpy张量会共享它们底层的内存，所以两个会同步修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35beab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wxy\\AppData\\Local\\Temp\\ipykernel_22880\\3580609473.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  B=torch.tensor(q)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=q.numpy()\n",
    "B=torch.tensor(q)\n",
    "type(A),type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ecc87",
   "metadata": {},
   "source": [
    "要将大小为1的张量转换为python标量，我们可以调用item函数以及python内置函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a10abe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.tensor([3.5])\n",
    "a,a.item(),float(a),int(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
